### 總覽
本模組彙總 RAG 在「檢索後處理」階段的三大能力：重排（Re-ranking）、壓縮（Compression）、校正（Corrective）。重排提升候選排序品質，壓縮降低下游 LLM 輸入成本，校正在檢索不佳時自動補救，三者可按需組合以達成準確、經濟且穩健的生成。

### 流程圖
```mermaid
flowchart TD
  Q[Query] --> RET[初檢索(向量/BM25/混合)]
  RET --> R[重排: RRF/CrossEncoder/ColBERT/Cohere/RankLLM/時效加權]
  R --> C[壓縮: ContextualCompression\nLLMLingua\nSentenceEmbeddingOptimizer]
  C --> G[生成(LLM)]
  R -->|候選全不相關| CRAG[CRAG 校正: 重寫查詢 + 網路搜索] --> C
```

### 分步講解
- 重排（精排）
  - RRF：融合多查詢/多路檢索結果，穩健、成本低。
  - CrossEncoder：Q+D 合併編碼，高精度，高成本，適合二階段精排。
  - ColBERT：後期交互、可預編碼文檔，兼顧效能與精度。
  - Cohere Rerank：雲端 API，多語表現佳，工程接入簡單。
  - RankLLM：以 LLM 推理做排序，精度高成本高，適用高價值查詢。
  - 時效加權：將時間新鮮度納入排序，適合新聞/動態知識庫。

- 壓縮（降本）
  - ContextualCompressionRetriever：以重排/摘要作為壓縮器，僅留關鍵片段。
  - LLMLingua：面向長文本/JSON 的壓縮，顯著降 token，保留要點。
  - SentenceEmbeddingOptimizer：相似度裁剪（百分位/閾值），去噪降長度。

- 校正（穩健）
  - CRAG：若候選均不相關，觸發「重寫查詢 → 網路搜索 → 再生成」，降低幻覺。

### 方案選型對比

| 類別 | 方法 | 優勢 | 成本/延遲 | 適用場景 |
|---|---|---|---|---|
| 重排 | RRF | 穩健、易實作 | 低 | 多查詢融合、快速提升覆蓋 |
| 重排 | CrossEncoder | 高精度細粒度交互 | 中-高 | Top-K 精排、答案質量優先 |
| 重排 | ColBERT | 可預編碼文檔、查詢延遲低 | 中 | 大規模檢索、兼顧效能與精度 |
| 重排 | Cohere Rerank | 多語強、工程接入簡單 | 付費/網路 | 商用快速落地、多語文本 |
| 重排 | RankLLM | 可解釋、複雜語義/推理 | 高 | 高價值問答、精度極致優先 |
| 重排 | 時效加權 | 新鮮度感知 | 低 | 新聞/動態知識庫/最新內容 |
| 壓縮 | ContextualCompression | 精排即壓縮，直連檢索器 | 低-中 | 控制 LLM 輸入長度、即插即用 |
| 壓縮 | LLMLingua | 大幅降 token，支援 JSON | 中 | 極長上下文/結構化資料壓縮 |
| 壓縮 | SentenceEmbeddingOptimizer | 去噪簡單有效 | 低 | 回答品質穩定、輸入適中 |
| 校正 | CRAG | 自我糾錯，降低幻覺 | 中 | 本地檢索不穩、需要外搜補救 |

### 快速選型建議
- 低延遲優先：RRF 或 ColBERT；再加 SentenceEmbeddingOptimizer。
- 高精度優先：向量/混合初檢索 → CrossEncoder/RankLLM 精排 → ContextualCompression。
- 多語/工程快：BM25/向量 → Cohere Rerank → ContextualCompression。
- 時效場景：在檢索器或重排階段加入「時效加權」。
- 檢索不穩：接入 CRAG 校正分支以保底。

### 代碼地圖（對應本模組）
- 重排：`01-重排/01-RRF重排.py`、`02-CrossEncoder重排.py`、`03-CoBERT重排.py`、`04-Cohere重排.py`、`05-RankLLM重排.py`、`06-时效加权重排.py`
- 壓縮：`02-压缩/01-ContextualCompressionRetriever压缩.py`、`02-LLMLingua压缩.py`、`03-SentenceEmbeddingOptimizer压缩.py`
- 校正：`03-校正/01-CRAG-反思式检索.py`

### 關鍵點總結
- **重排** 提升排序準確性，按精度/成本選擇 CrossEncoder、ColBERT、Cohere、RankLLM、RRF、時效加權。
- **壓縮** 控制輸入成本，優先使用檢索端壓縮（ContextualCompression），必要時加 LLMLingua/SEO。
- **校正** 用 CRAG 彌補檢索缺陷，形成「穩健路徑」。實務中可與評估指標結合觀測與調參。


