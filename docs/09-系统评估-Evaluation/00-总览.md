### 總覽
本模組整理 RAG 系統在「評估與可觀測」層的常用方案：RAGAS（離線指標評估）、TruLens（在線可觀測 + 反饋指標）、DeepEval（單元級指標測試）與 LlamaIndex 原生評測（端到端 A/B）。

### 關係圖
```mermaid
flowchart TD
  subgraph 指標庫
    A[RAGAS\nFaithfulness/AnswerRelevancy]
    B[DeepEval\nContextualPrecision/AnswerRelevancy]
  end
  subgraph 可觀測
    C[TruLens\n@instrument + Feedback + Leaderboard]
  end
  subgraph 框架內建
    D[LlamaIndex Evaluation\nCorrectness/Faithfulness/Relevancy/SemanticSimilarity]
  end
  DATA[測試數據/QR Pairs] --> A & B & D
  APP[RAG App] --> C
```

### 方法對比表

| 類別 | 工具 | 優勢 | 成本/延遲 | 適用場景 |
|---|---|---|---|---|
| 離線評估 | RAGAS | 指標成熟、覆蓋常見度量 | 低-中 | 批量測試、Embedding 對比 |
| 在線觀測 | TruLens | 鏈路可見、版本對比、理由化分數 | 中 | 線上觀測、AB 迭代評估 |
| 單元測試 | DeepEval | 輕量、CI 友好 | 低 | Prompt/邏輯改動的冒煙/回歸 |
| 內建評估 | LlamaIndex | 與檢索引擎集成緊密 | 中 | 檢索策略與後處理 A/B |

### 推薦實踐
- 開發期：DeepEval 做最小測；RAGAS 小樣本跑通指標與資料流。
- 調優期：TruLens 接入線上可觀測，對比不同版本提示/模型/檢索策略。
- 上線後：定期離線抽樣 + 線上分流實驗，形成評估報表。

### 代碼地圖
- `01-RAGAS.py`、`02-Trulens.py`、`03-DeepEval.py`、`04-LlamaIndexEvaluation.py`


