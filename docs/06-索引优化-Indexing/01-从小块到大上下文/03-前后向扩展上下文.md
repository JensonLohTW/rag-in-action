### 總覽
展示 LlamaIndex 的「前後向上下文擴展」兩種方式：固定窗口 `PrevNextNodePostprocessor(num_nodes=2)` 與自動窗口 `AutoPrevNextNodePostprocessor(num_nodes=3)`，對比基礎引擎的回答效果。

### 流程圖
```mermaid
flowchart TD
  D[Document] --> SP[SentenceSplitter]
  SP --> N[Nodes]
  N --> DS[SimpleDocumentStore]
  N --> IDX[VectorStoreIndex]
  Q[Query] --> B[base_engine\nsimilarity_top_k=1]
  Q --> P[prev_next_engine\nPrevNextNodePostprocessor(num_nodes=2)]
  Q --> A[auto_engine\nAutoPrevNextNodePostprocessor(num_nodes=3)]
  IDX --> B & P & A
```

### 分步講解
- 節點與存儲：`SentenceSplitter` → `SimpleDocumentStore` → `VectorStoreIndex`。
- 三種查詢引擎：
  - 基礎引擎：僅返回命中節點的摘要式回答。
  - 固定前後文：固定擴展前後相鄰節點，補足上下文。
  - 自動前後文：根據檢索結果自動選擇更合適的前後文，`verbose=True` 便於觀測。

### 關鍵點總結
- **上下文補全**：對長敘事文本（小說、傳記）更友好。
- **可控性**：固定窗口可預測，自動窗口更靈活。
- **調參**：`similarity_top_k` 與 `num_nodes` 需配合調整。


